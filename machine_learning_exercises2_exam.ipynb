{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handout_ml_exercises2_2020",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIxvd5gAbHs9",
        "colab_type": "text"
      },
      "source": [
        "# # Exercises for Machine Learning with Python, Lecture 2: *Kernel Ridge Regression and Molecules*\n",
        "By Dr. Anders Christensen `anders.christensen @ unibas.ch`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxObaV68_Cww",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "# ***Important:***\n",
        "\n",
        "***The answers to the questions must be entered in the online system.***\n",
        "\n",
        "https://www.chemie1.unibas.ch/~pythonprakt/\n",
        "\n",
        "*    You should have received the username and password by email.\n",
        "*    Use you @unibas.ch or @stud.unibas.ch email to login after you enter the username and password for the course.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BGzfzjFbr6T",
        "colab_type": "text"
      },
      "source": [
        "## Before you begin the exercises:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA9yO2Grb04O",
        "colab_type": "text"
      },
      "source": [
        "Again, we begin by downloading a dataset. This dataset is taken from the \"QM7\" dataset introduced in the lecture. \n",
        "\n",
        "As there are 7101 molecules in the datasets, all the data is stored in binary format to keep the files small enough for Google Colab. The data format is Numpy's \".npy\" format.\n",
        "\n",
        "The data consists of representations (aka. features) for each of the 7101 molecules, and also the atomization energy of each molecule (i.e. how much energy it takes to break the molecule into its free atoms). \n",
        "\n",
        "There are two sets of representations, the Coulomb Matrix representation and the Bag-of-Bonds representation, and later you will compare which of the two is best for predicting the atomization energy with Kernel Ridge Regression.\n",
        "\n",
        "**To-do:**\n",
        "\n",
        "*    Download the binary datafiles with the \"wget\" command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euXS0zHjIhZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download features maps and labels:\n",
        "!wget -O cmat.npy https://www.dropbox.com/s/4eqafm0yr2ywxps/cmat.npy\n",
        "!wget -O bob.npy https://www.dropbox.com/s/vyiwza2uy4jkczg/bob.npy\n",
        "!wget -O hof.npy https://www.dropbox.com/s/zy717f8mwxaegff/hof.npy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uln6afLhlDez",
        "colab_type": "text"
      },
      "source": [
        "Next, Numpy can directly read .npy files and convert these into Numpy arrays using the `np.load()` function.\n",
        "\n",
        "**To-do:**\n",
        "\n",
        "*   Run the code below to read in the features as numpy arrays and print their sizes and types:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlYAuuUdb4Aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Save 'Coulomb matrices' features in 'cmat_features'\n",
        "cmat_features = np.load(\"cmat.npy\")\n",
        "\n",
        "# Save 'Bag-of-Bonds' features in 'bob_features'\n",
        "bob_features = np.load(\"bob.npy\")\n",
        "\n",
        "# Save Atomization Energies in 'hof'\n",
        "atomization_energy = np.load(\"hof.npy\")\n",
        "\n",
        "# Print the dimensions and type of each numpy array, just to see what you got\n",
        "print(cmat_features.shape)\n",
        "print(type(cmat_features))\n",
        "\n",
        "print(bob_features.shape)\n",
        "print(type(bob_features))\n",
        "\n",
        "print(atomization_energy.shape)\n",
        "print(type(atomization_energy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD47mLCuluNm",
        "colab_type": "text"
      },
      "source": [
        "As you can see above, each Numpy array contains 7101 rows. Each row in the Coulomb-matrix representation has 276 features and each row in the Bag-of-bonds representation has 465 features.\n",
        "\n",
        "The 7101 heats-of-formation are in units of kcal/mol.\n",
        "\n",
        "Additionally, you can print all the arrays, just to see what they contain (a lot of numbers).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3y5x_WYta_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cmat_features)\n",
        "print(bob_features)\n",
        "print(atomization_energy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmdYdgtumgry",
        "colab_type": "text"
      },
      "source": [
        "# Exercises 2.1: Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yob-kF-Wmq32",
        "colab_type": "text"
      },
      "source": [
        "As we've done during the lecture, lets's start by having a look at your data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLEvUSigby0F",
        "colab_type": "text"
      },
      "source": [
        "### Question 2.1.1: (6.1)\n",
        "\n",
        "Since we've already looked into the representation during the lecture, we will skip looking at plots for them those for now.\n",
        "\n",
        "However, to make sure that we trust our data, we still want to plot a histogram of the labels.\n",
        "\n",
        "**To-do:**\n",
        "*    Using matplotlib/pyplot, plot a histogram of the `atomization_energy` array\n",
        "*    In the web-interface, answer the following question:  *What is the value range of the atomization energies?*\n",
        "\n",
        "**Note:** The atomization energies are in units of kcal/mol."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkkUBqsAnqkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the histogram of the atomization energies\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAJTmB6qpxc7",
        "colab_type": "text"
      },
      "source": [
        "# Exercises 2.2: Training/Validation/Test split:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIsTo0IFso1S",
        "colab_type": "text"
      },
      "source": [
        "Before we do any training and optimization, it is a good idea to split the data in to a training set, a validation set, and a test set.\n",
        "\n",
        "Since our representations (the Coulomb Matrix featuers, and the Bag-of-Bonds features) and the atomization energy labels are in Numpy format, you can do the splitting utilizing Numpy's \"slice\" notation. \n",
        "\n",
        "Below are some examples of how to get certain rows out of a matrix which you can use for inspiration\n",
        "\n",
        "```\n",
        "# Get rows 0-9:\n",
        "rows1 = my_matrix[:10]\n",
        "\n",
        "# Get rows 10-19\n",
        "rows2 = my_matrix[10:20]\n",
        "\n",
        "# Get rows 20 and onwards\n",
        "rows2 = my_matrix[20:]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcdP5cGmwbpJ",
        "colab_type": "text"
      },
      "source": [
        "### Question 2.2.1:  (6.2)\n",
        "\n",
        "In this question, you have to split the three Numpy arrays `cmat_features`, `bob_features`, and `atomization_energy` each into a training, a validation and a test part. In total you will end up with 9 numpy arrays in total.\n",
        "\n",
        "**Note:** It is important that no molecule is in more than one set.\n",
        "\n",
        "**To-do:**\n",
        "*    Split the data into Training/Validation/Test sets of roghly 60%/20%/20% of the total dataset each.\n",
        " \n",
        "*    How many molecules are there the training, validation and test sets with a 60%/20%/20% split? In the web-interface select the right answer.\n",
        " * Since the sizes of splits can vary slightly depending on how you did the splitting, choose the option that is closest to what you found.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3HaxLklxXe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the splits here\n",
        "\n",
        "# Split the coulomb matrix features\n",
        "cmat_features_training = ???\n",
        "cmat_features_validation = ???\n",
        "cmat_features_test = ???\n",
        "\n",
        "# Split the bag-of-bond features\n",
        "bob_features_training = ???\n",
        "bob_features_validation = ???\n",
        "bob_features_test = ???\n",
        "\n",
        "# Split the atomization energies\n",
        "atomization_energy_training = ???\n",
        "atomization_energy_validation = ???\n",
        "atomization_energy_test = ???\n",
        "\n",
        "# Print sizes of the three data splits)\n",
        "print(len(atomization_energy_training))\n",
        "print(len(atomization_energy_validation))\n",
        "print(len(atomization_energy_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zLuPFikS9Vb",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2.3: Kernel Ridge Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwLldIMTTC6F",
        "colab_type": "text"
      },
      "source": [
        "Now that we have defined our training, validation and test splits, we are now ready to fit a kernel ridge regresssion model. \n",
        "\n",
        "Just like the previous examples with classifiers and linear regression, Scikit-Learn has built-in support for kernel ridge regresssion. Below is some boiler-plate code you can use:\n",
        "\n",
        "```\n",
        "# Import the Machine\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "\n",
        "# Make a machine, see text for explanation of key-words\n",
        "machine = KernelRidge(alpha=1e-9, kernel=\"rbf\", gamma=1e-4)\n",
        "\n",
        "# Fit the machine using the training features and training labels\n",
        "machine.fit(features_training, labels_training)\n",
        "```\n",
        "With the fitted macine, you can now make predictions for a set of test features and get the predicted labels from your machine:\n",
        "\n",
        "\n",
        "```\n",
        "# Predict y-values using features_training features\n",
        "labels_test_predicted = machine.predict(features_test)\n",
        "```\n",
        "\n",
        "If you paid attention to the keyword arguments for the machine `KernelRidge(alpha=1e-9, kernel=\"rbf\", gamma=1e-4)`, an explanation is given here:\n",
        "\n",
        "\n",
        "1.   `alpha=1e-9` is the regularizer, i.e. the small number to add to the diagonal of the kernel matrix. $10^{-9}$ is a good value for many problems and we don't have to optimize this. \n",
        "2.   `kernel=\"rbf\"` Another word for Gaussian kernel function is also the radial basis function (RBF). This keyword tells the machine to use the Gaussian kernel.\n",
        "3.   `gamma=1e-4` Gamma (i.e. $\\gamma$) is the length scale of Gaussian/radial basis function. \n",
        "\n",
        "The kernel used in Scikit-learn is defined as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "K\\left(\\mathbf{x}_i, \\mathbf{x}_j\\right) = \\exp\\left( -\\gamma \\|x - y \\|^2 \\right)\n",
        "\\end{equation}\n",
        "Later, we will optimize the value of $\\gamma$ to ensure the most accurate machine learning mode.\n",
        "\n",
        "The accuracy of a machine learning model can be assessed, for example, by calculating the mean-absolute-error (MAE) for a test or validation set:\n",
        "\\begin{equation}\n",
        "\\text{MAE} = \\frac{1}{N}\\sum_{i=1}^N |y_i^{true} - y_i^{predicted} |\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBBvleN6iToc",
        "colab_type": "text"
      },
      "source": [
        "### Question 2.3.1:  (6.3)\n",
        "Make a kernel ridge regression machine as described above. \n",
        "\n",
        "Use the same parameters values as in the example above, that is `alpha=1e-9, kernel=\"rbf\", gamma=1e-4`.\n",
        "\n",
        "\n",
        "**To-do:**\n",
        "* First, train your model on the training set with Coulomb Matrix features (i.e. `cmat_features_training` and `atomization_energy_training`). \n",
        "* Next predict the atomization energy on the test set (`cmat_features_test`), and calculate the mean-absolute-error (MAE) between the predicted atomization energies for the test set and the true atomization energies (stored in `atomization_energy_test`).\n",
        "* In the web interface, enter the MAE of the atomization energies you calculated using Coulomb matrix features.\n",
        " * You are allowed a margin of +/- 4 kcal/mol since the numbers might vary slightly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDnzWRmTK23S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.kernel_ridge import KernelRidge\n",
        "\n",
        "# Implement kernel ridge regression model \n",
        "# Train the model on cmat_features_training and atomization_energy_training\n",
        "\n",
        "\n",
        "\n",
        "# Predict atomization energies on cmat_features_test\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the MAE between the predicted and true atomization energies for the test set\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSozsQbpWUhd",
        "colab_type": "text"
      },
      "source": [
        "### Question 2.3.2:   (6.4)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffLSCfv3WXcz",
        "colab_type": "text"
      },
      "source": [
        "Repeat what you did in Question 2.3.1, but this time train on the training set with Bag-of-Bonds features \n",
        "\n",
        "\n",
        "* Train your kernel ridge regression using `bob_features_training` and `atomization_energy_training`. \n",
        "* Next predict the atomization energy on the test set (`bob_features_test`), and calculate the mean-absolute-error (MAE) between the predicted atomization energies for the test set and the true atomization energies (stored in `atomization_energy_test`).\n",
        "* In the web interface, enter the MAE of the atomization energies you calculated using Bag-of-Bonds features.\n",
        " * You are allowed a margin of +/- 4 kcal/mol since the numbers might vary slightly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC6qsPt9nRI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.kernel_ridge import KernelRidge\n",
        "\n",
        "# Implement kernel ridge regression model \n",
        "# Train the model on bob_features_training and atomization_energy_training\n",
        "\n",
        "\n",
        "\n",
        "# Predict atomization energies on bob_features_test\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the MAE between the predicted and true atomization energies for the test set\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2v7KXk8Pr8L",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2.4: Hyperparameter Optimizaton.\n",
        "\n",
        "In order to ensure the most accurate predictions we need to optimize the hyperparameters of the model. Kernel ridge regression models can be especially sensitive to the length-scale parameter, in our case the parameter $\\gamma$ (`gamma`).\n",
        "\n",
        "To set the value of gamma in the machine learning mode to, for example, $10^{-8}$ you can change the argument `gamma=` as follows:\n",
        "\n",
        "```\n",
        "machine = KernelRidge(alpha=1e-9, kernel=\"rbf\", gamma=1e-8)\n",
        "```\n",
        "\n",
        "One common strategy to optimize such parameter is to scan all parameters over a logarithmically-space range.\n",
        "\n",
        "To avoid overfitting (i.e. fitting parameters to the test set), it is common practice to train the model on the test set and predict on the *validation* set. The best/optimal value is the parameter with the lowest prediction error on the validation set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t66AyY2rPrR",
        "colab_type": "text"
      },
      "source": [
        "### Question 2.4.1: (6.5)\n",
        "Previously, we only trained machines for only for `gamma=1e-4`. In this question, you will train machines for $\\gamma$ in a range between $1.0$ down to $10^{-9}$ (see code). First, we do this for the Coulomb matrix features.\n",
        "\n",
        "**To-do:**\n",
        "* For each value of `gamma`, train a machines on the training set using the Coulomb Matrix features, i.e. `cmat_features_trainig`.\n",
        "* For each value of `gamma`, predict the atomization energy for the validation set, using Coulomb Matrix features, i.e. `cmat_features_validation`.\n",
        "* Next, calculate the mean-absolute-error between the predicted and true atomization energies for the validation set.\n",
        "* In the web-interface, select which values of `gamma` you found to give the lowest MAE using Coulomb matrix features.\n",
        " * Note: As some values of `gamma` will give MAE values that are very close, there are several right answers to this question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqfMU20JrPRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The list of Gamma that we wish to try\n",
        "gammas = [1.0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9]\n",
        "\n",
        "# Kernel ridge regression models for each gamma on cmat_features_trainig\n",
        "# Predict on the atomization energy for cmat_features_validation\n",
        "# Calculate the MAE between the true and predicted atomization energies\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bcsCzV_hwY_H"
      },
      "source": [
        "### Question 2.4.2:  (6.6)\n",
        "In the previous question, you found the best value of `gamma` for Coulomb matrix features. In this question you will repeat the same process and find the opimal value of `gamma` for the Bag-of-Bonds features.\n",
        "\n",
        "**To-do:**\n",
        "* For each value of `gamma`, train a machines on the training set using the Bag-of-Bonds features, i.e. `bob_features_trainig`.\n",
        "* For each value of `gamma`, predict the atomization energy for the validation set, using Bag-of-Bonds features, i.e. `bob_features_validation`.\n",
        "* Next, calculate the mean-absolute-error between the predicted and true atomization energies for the validation set.\n",
        "* In the web-interface, select which values of `gamma` you found to give the lowest MAE using Bag-of-Bonds features.\n",
        " * Note: As some values of `gamma` will give MAE values that are very close, there are several right answers to this question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nyn9gUuewY_K",
        "colab": {}
      },
      "source": [
        "# The list of Gamma that we wish to try\n",
        "gammas = [1.0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9]\n",
        "\n",
        "# Kernel ridge regression models for each gamma on bob_features_trainig\n",
        "# Predict on the atomization energy for bob_features_validation\n",
        "# Calculate the MAE between the true and predicted atomization energies\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us1TYPIDbFMj",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2.5: Learning Curves\n",
        "\n",
        "In order to see which of the two reprsentations  (Coulomb Matrix and Bag-of-Bonds) gives the most accurate kernel ridge regression model, we can compare learning curves for the machines based on the two representations.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INaexoWW1sMc",
        "colab_type": "text"
      },
      "source": [
        "### Question 2.5.1: (6.7)\n",
        "For both representations, train machines using 500, 1000, 2000, and 4000 molecules from the training set. Use the best value of `gamma` which you found in the previous exercise for each machine.\n",
        "\n",
        "Again, use Numpy's slice notation to extract only the neccesary number of rows from the Numpy arrays in the training set.\n",
        "\n",
        "\n",
        "**To-do:**\n",
        "*   Train machines for each training set size with the two representation (Coulomb Matrix and Bag-of-bonds)\n",
        "*   For each machine you train, predict the atomization energy for the test set and calculate the mean-absolue-error (MAE) to the true energies for the test set.\n",
        "*   Plot the MAE values as a function of the training set size.\n",
        "*   The representation which yields the most accurate predictions is the one with the lowest learning curve. In the web interface, select the representation that gave you the learning curves with the lowest MAE values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFXFjC3Z3RJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement learning curves for kernel ridge regression here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}